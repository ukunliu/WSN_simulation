{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cirs = np.load('cirs_noised_ld.npy')\n",
    "cirs_obs = np.load('cirs_observation_ld.npy')\n",
    "triplets = np.load('triplets_ld.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "miu, sigma = cirs.mean(), cirs.var()\n",
    "\n",
    "cirs = (cirs - cirs.min()) / (cirs.max() - cirs.min())\n",
    "cirs_obs = (cirs_obs - cirs_obs.min()) / (cirs_obs.max() - cirs_obs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([cirs_obs[trp[0]] for trp in triplets])\n",
    "Pi = np.array([cirs[trp[1]] for trp in triplets])\n",
    "Pj = np.array([cirs[trp[2]] for trp in triplets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_hinge(p, pi, pj, W, margin=1):\n",
    "    return max(0, margin - p.T @ W @ pi + p.T @ W @ pj)\n",
    "\n",
    "def loss_global(triplets, W, cirs, cirs_obs):\n",
    "    return np.sum([loss_hinge(cirs_obs[i0], cirs[i1], cirs[i2], W) for i0, i1, i2 in triplets])\n",
    "\n",
    "def gradient(W, P, Pi, Pj):\n",
    "    grad = np.zeros_like(W)\n",
    "\n",
    "def gradient_descent():\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Algorithm for Scalable Image Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1000\n",
    "margin = 1e4\n",
    "n, d = cirs.shape # number of samples, dimension of samples\n",
    "theta = np.ones((d, d)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [loss_0]\n",
    "\n",
    "for ind_0, ind_1, ind_2 in t:\n",
    "    p, pi, pj = c_o[ind_0], c[ind_1], c[ind_2]\n",
    "    v = p * (pi - pj)\n",
    "    tau = min(C, loss_hinge(p, pi, pj, theta, margin) / (v.T @ v))\n",
    "    theta = theta + tau * v\n",
    "    loss.append(loss_global(triplets, theta, cirs, cirs_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hinge(p, pi, pj, theta, margin) / (v.T @ v)\n",
    "loss_hinge(p, pi, pj, theta, margin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet loss with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Dense\n",
    "from tensorflow.keras.layers import Lambda, Dot\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"Ignore y_true and return the mean of y_pred\n",
    "    \n",
    "    This is a hack to work-around the design of the Keras API that is\n",
    "    not really suited to train networks with a triplet loss by default.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(y_pred)\n",
    "\n",
    "\n",
    "class MarginLoss(layers.Layer):\n",
    "\n",
    "    def __init__(self, margin=1.):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        pos_pair_similarity = inputs[0]\n",
    "        neg_pair_similarity = inputs[1]\n",
    "        \n",
    "        diff = neg_pair_similarity - pos_pair_similarity\n",
    "        print(diff)\n",
    "        return tf.maximum(diff + self.margin, 0.)\n",
    "\n",
    "\n",
    "class TripletModel(Model):\n",
    "    def __init__(self, n_observation, n_comparison, margin=1., l2_reg=None):\n",
    "        super().__init__(name=\"TripletModel\")\n",
    "        \n",
    "        self.margin = margin\n",
    "        \n",
    "        l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "        self.obs_layer = Input((n_observation, ), name='observation layer')\n",
    "        # self.obs_layer = Embedding(n_observation, n_observation,\n",
    "        #                             input_length=n_observation,\n",
    "        #                             input_shape=(n_observation,),\n",
    "        #                             name='obs_embedding',\n",
    "        #                             embeddings_regularizer=l2_reg)\n",
    "        self.comp_layer = Input((n_comparison, ), name='comparisons layer')\n",
    "\n",
    "        # self.comp_layer = Embedding(n_comparison, n_comparison,\n",
    "        #                             input_length=n_comparison,\n",
    "        #                             input_shape=(n_comparison,),\n",
    "        #                             name='comp_embedding',\n",
    "        #                             embeddings_regularizer=l2_reg)\n",
    "\n",
    "        self.dot = Dot(axes=1, normalize=True)\n",
    "\n",
    "        self.margin_loss = MarginLoss(margin)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        observation = inputs[0]\n",
    "        pos_compare = inputs[1]\n",
    "        neg_compare = inputs[2]\n",
    "        \n",
    "        obs_input = self.obs_layer(observation)\n",
    "        \n",
    "        pos_input = self.comp_layer(pos_compare)\n",
    "        \n",
    "        neg_input = self.comp_layer(neg_compare)\n",
    "        \n",
    "        # Similarity computation between embeddings\n",
    "        pos_similarity = self.dot([obs_input, pos_input])\n",
    "        neg_similarity = self.dot([obs_input, neg_input])\n",
    "                \n",
    "        return self.margin_loss([pos_similarity, neg_similarity])\n",
    "    \n",
    "\n",
    "def average_roc_auc(model, data_train, data_test):\n",
    "    \"\"\"Compute the ROC AUC for each user and average over users\"\"\"\n",
    "    max_user_id = max(data_train['user_id'].max(),\n",
    "                      data_test['user_id'].max())\n",
    "    max_item_id = max(data_train['item_id'].max(),\n",
    "                      data_test['item_id'].max())\n",
    "    user_auc_scores = []\n",
    "    for user_id in range(1, max_user_id + 1):\n",
    "        pos_item_train = data_train[data_train['user_id'] == user_id]\n",
    "        pos_item_test = data_test[data_test['user_id'] == user_id]\n",
    "        \n",
    "        # Consider all the items already seen in the training set\n",
    "        all_item_ids = np.arange(1, max_item_id + 1)\n",
    "        items_to_rank = np.setdiff1d(\n",
    "            all_item_ids, pos_item_train['item_id'].values)\n",
    "        \n",
    "        # Ground truth: return 1 for each item positively present in\n",
    "        # the test set and 0 otherwise.\n",
    "        expected = np.in1d(\n",
    "            items_to_rank, pos_item_test['item_id'].values)\n",
    "        \n",
    "        if np.sum(expected) >= 1:\n",
    "            # At least one positive test value to rank\n",
    "            repeated_user_id = np.empty_like(items_to_rank)\n",
    "            repeated_user_id.fill(user_id)\n",
    "\n",
    "            predicted = model.predict(\n",
    "                [repeated_user_id, items_to_rank], batch_size=4096)\n",
    "        \n",
    "            user_auc_scores.append(roc_auc_score(expected, predicted))\n",
    "\n",
    "    return sum(user_auc_scores) / len(user_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(triplets, cir_obs, cir_base, random_seed=0):\n",
    "    obs, pos_comp, neg_comp = [], [], []\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    for i, j, _ in triplets:\n",
    "        obs.append(cir_obs[i])\n",
    "        pos_comp.append(cir_base[j])\n",
    "\n",
    "    neg_comp = cir_base[rng.randint(low=0, high=len(cirs), size=len(triplets))]\n",
    "\n",
    "    return [np.array(obs), np.array(pos_comp), np.array(neg_comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = triplet_inputs\n",
    "new_trip = [np.transpose(a), np.transpose(b), np.transpose(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 400, 675), (400,), (3, 675, 400), (400, 3, 675))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(triplet_inputs), np.shape(fake_y), np.shape(new_trip), np.shape(new_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "dim_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletModel(Model):\n",
    "    def __init__(self, n_observation, n_comparison, margin=1., latent_dim=64, l2_reg=None):\n",
    "        super().__init__(name=\"TripletModel\")\n",
    "        \n",
    "        self.margin = margin\n",
    "        \n",
    "        l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "        # self.obs_layer = Input((n_observation, ), name='observation layer')\n",
    "        self.obs_layer = Embedding(n_observation, n_observation,\n",
    "                                    name='obs_embedding',\n",
    "                                    embeddings_regularizer=l2_reg)\n",
    "        # self.comp_layer = Input((n_comparison, ),name='comparisons layer')\n",
    "        self.comp_layer = Embedding(n_comparison, n_comparison,\n",
    "                            name='comp_embedding',\n",
    "                            embeddings_regularizer=l2_reg)\n",
    "\n",
    "        self.dot = Dot(axes=1, normalize=True)\n",
    "\n",
    "        self.margin_loss = MarginLoss(margin)\n",
    "\n",
    "        self.dense = Dense(latent_dim, activation='relu')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        observation = inputs[0]\n",
    "        pos_compare = inputs[1]\n",
    "        neg_compare = inputs[2]\n",
    "        \n",
    "        obs_input = self.obs_layer(observation)\n",
    "        \n",
    "        pos_input = self.comp_layer(pos_compare)\n",
    "        \n",
    "        neg_input = self.comp_layer(neg_compare)\n",
    "\n",
    "        # latent feature\n",
    "        obs = self.dense(obs_input)\n",
    "        pos = self.dense(pos_input)\n",
    "        neg = self.dense(neg_input)\n",
    "        \n",
    "        # Similarity computation between embeddings\n",
    "        pos_similarity = self.dot([obs, pos])\n",
    "        neg_similarity = self.dot([obs, neg])\n",
    "                \n",
    "        return self.margin_loss([pos_similarity, neg_similarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TripletModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " obs_embedding (Embedding)   multiple                  455625    \n",
      "                                                                 \n",
      " comp_embedding (Embedding)  multiple                  455625    \n",
      "                                                                 \n",
      " dot_64 (Dot)                multiple                  0         \n",
      "                                                                 \n",
      " margin_loss_64 (MarginLoss)  multiple                 0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            multiple                  43264     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 954,514\n",
      "Trainable params: 954,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"TripletModel/margin_loss_64/sub:0\", shape=(None, 64, 64), dtype=float32)\n",
      "Tensor(\"TripletModel/margin_loss_64/sub:0\", shape=(None, 64, 64), dtype=float32)\n",
      "7/7 [==============================] - 5s 535ms/step - loss: 1.0008\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0007\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0007\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0007\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0007\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 1.0007\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0006\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 1.0006\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 1.0005\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0005\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.0005\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0005\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0004\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0004\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0004\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0003\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 1.0003\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0003\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.0003\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.0002\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 1.0001\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 480ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 1.0000\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fake_y = np.ones(len(cirs))\n",
    "\n",
    "dim_obs = cirs_obs.shape[1]\n",
    "dim_comp = cirs.shape[1]\n",
    "\n",
    "triplet_model = TripletModel(dim_obs, dim_comp, l2_reg=1e-6)\n",
    "\n",
    "triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # Sample new negatives to build different triplets at each epoch\n",
    "    triplet_inputs = sample_triplets(triplets, cirs_obs, cirs, random_seed=i)\n",
    "\n",
    "    # Fit the model incrementally by doing a single pass over the\n",
    "    # sampled triplets.\n",
    "    triplet_model.fit(x=triplet_inputs, y=fake_y, shuffle=True,\n",
    "                      batch_size=64, epochs=1, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x172cc832388>]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Generate dummy data\n",
    "num_samples = 400\n",
    "input_shape = (675,)\n",
    "X1 = np.random.rand(num_samples, *input_shape)\n",
    "X2 = np.random.rand(num_samples, *input_shape)\n",
    "X3 = np.random.rand(num_samples, *input_shape)\n",
    "Y = np.random.rand(num_samples, 1)\n",
    "\n",
    "# Define the model\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "input3 = Input(shape=input_shape)\n",
    "\n",
    "x = Dense(128, activation='relu')(input1)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "y = Dense(128, activation='relu')(input2)\n",
    "y = Dense(64, activation='relu')(y)\n",
    "y = Dense(32, activation='relu')(y)\n",
    "\n",
    "z = Dense(128, activation='relu')(input3)\n",
    "z = Dense(64, activation='relu')(z)\n",
    "z = Dense(32, activation='relu')(z)\n",
    "\n",
    "merged = layers.concatenate([x, y, z])\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "model = Model(inputs=[input1, input2, input3], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X1, X2, X3], Y, batch_size=32, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss = model.evaluate([X1, X2, X3], Y)\n",
    "print(\"Test loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filexm3dzdu5.py\", line 10, in tf__call\n        x1 = ag__.converted_call(ag__.ld(self).input1, (ag__.ld(inputs)[0],), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"trip_2\" (type Trip).\n    \n    in user code:\n    \n        File \"<ipython-input-396-ac53be10c660>\", line 15, in call  *\n            x1 = self.input1(inputs[0])\n    \n        TypeError: 'KerasTensor' object is not callable\n    \n    \n    Call arguments received by layer \"trip_2\" (type Trip):\n      • inputs=('tf.Tensor(shape=(None, 675), dtype=float32)', 'tf.Tensor(shape=(None, 675), dtype=float32)', 'tf.Tensor(shape=(None, 675), dtype=float32)')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-398-ac53be10c660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexm3dzdu5.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filexm3dzdu5.py\", line 10, in tf__call\n        x1 = ag__.converted_call(ag__.ld(self).input1, (ag__.ld(inputs)[0],), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"trip_2\" (type Trip).\n    \n    in user code:\n    \n        File \"<ipython-input-396-ac53be10c660>\", line 15, in call  *\n            x1 = self.input1(inputs[0])\n    \n        TypeError: 'KerasTensor' object is not callable\n    \n    \n    Call arguments received by layer \"trip_2\" (type Trip):\n      • inputs=('tf.Tensor(shape=(None, 675), dtype=float32)', 'tf.Tensor(shape=(None, 675), dtype=float32)', 'tf.Tensor(shape=(None, 675), dtype=float32)')\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "class Trip(Model):\n",
    "    def __init__(self):\n",
    "        super(Trip, self).__init__()\n",
    "        self.input1 = Input(shape=(675,))\n",
    "        self.input2 = Input(shape=(675,))\n",
    "        self.input3 = Input(shape=(675,))\n",
    "        self.d1 = Dense(64, activation='relu')\n",
    "        self.d2 = Dense(32, activation='relu')\n",
    "        self.output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.input1(inputs[0])\n",
    "        x2 = self.input2(inputs[1])\n",
    "        x3 = self.input3(inputs[2])\n",
    "        x = self.d1(x1)\n",
    "        x = self.d2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the Trip class\n",
    "trip = Trip()\n",
    "\n",
    "# Compile the model\n",
    "trip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Generate some sample data\n",
    "import numpy as np\n",
    "X1 = np.random.rand(400, 675)\n",
    "X2 = np.random.rand(400, 675)\n",
    "X3 = np.random.rand(400, 675)\n",
    "y = np.random.randint(0, 2, size=(400, 1))\n",
    "\n",
    "# Train the model\n",
    "trip.fit([X1, X2, X3], y, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (computer_vision)",
   "language": "python",
   "name": "pycharm-dac32f44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
