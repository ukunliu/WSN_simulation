{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from geopy.distance import geodesic\n",
    "import geopy.point as point\n",
    "import tqdm\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'sahara_small'\n",
    "meta_data = scipy.io.loadmat(f'./dataset/{location}_cell.mat')\n",
    "cir_profile = meta_data[f'{location}_cell']['cir'][0][0]\n",
    "dist = meta_data[f'{location}_cell']['dist'][0][0]\n",
    "\n",
    "Y = meta_data[f'{location}_cell'][0][0]['tx'].T # coordination of agents (lat, lon)\n",
    "RX = meta_data[f'{location}_cell'][0][0]['rx'].T\n",
    "p_a_arr = Y\n",
    "p_i_arr = RX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.special import erf \n",
    "from math import isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delay_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7a4e16bf02f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mP_E\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.5\u001b[0m \u001b[1;31m# weights of NL,E in NL,E and NL,M sources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e6\u001b[0m \u001b[1;31m# parameter for exponential distribution of NL,M, depending on channel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtheta_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mp_ai\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'delay_set' is not defined"
     ]
    }
   ],
   "source": [
    "def Q(x):\n",
    "    '''Gaussian Q function'''\n",
    "    return .5 - .5  * erf(x / np.sqrt(2))\n",
    "\n",
    "global p_NL, p_E, eta, theta_max\n",
    "p_NL = .5 # probability of all delays are from NLOS path\n",
    "P_E = .5 # weights of NL,E in NL,E and NL,M sources\n",
    "eta = 1e6 # parameter for exponential distribution of NL,M, depending on channel\n",
    "theta_max = max(delay_set)\n",
    "\n",
    "def p_ai(a_i, L):\n",
    "    if a_i == 0:\n",
    "        return p_NL\n",
    "    elif a_i > 0 and a_i <= L:\n",
    "        return (1 - p_NL) / L\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def f_L(theta, p_a, p_i):\n",
    "    return 1 if isclose(theta, geodesic(p_a, p_i).m / 3e8, rel_tol=.05) else 0\n",
    "\n",
    "def f_NL(theta, p_a, p_i):\n",
    "    theta_min = geodesic(p_a, p_i).m / 3e8\n",
    "    theta_max = max(delay_set) # predefined maximum possible delay\n",
    "    print(f_NLE(theta, theta_max), f_NLM(theta, theta_min, theta_max))\n",
    "    return P_E * f_NLE(theta, theta_max) + (1 - P_E) * f_NLM(theta, theta_min, theta_max)\n",
    "\n",
    "def f_NLM(theta, theta_min, theta_max):\n",
    "    return eta * np.exp(-eta * (theta - theta_min)) / (1 - np.exp(-eta * (theta_max - theta_min))) \\\n",
    "        if theta >= theta_min and theta < theta_max \\\n",
    "            else 0\n",
    "\n",
    "def f_NLE(theta, theta_max):\n",
    "    return 1 / theta_max if theta >= 0 and theta < theta_max else 0\n",
    "\n",
    "def f_anchor_i_ai(theta_arr, p_a, p_i, a_i):\n",
    "    '''conditional prob of anchor i given p_a, p_i, a_i \n",
    "    theta_arr reprents the entire theta arr in CIR for anchor i'''\n",
    "    return np.prod([f_NL(theta, p_a, p_i) for theta in theta_arr]) if a_i == 0 \\\n",
    "        else f_L(theta_arr[a_i]) * np.prod([f_NL(theta, p_a, p_i) for theta in theta_arr if theta != theta_arr[a_i]])\n",
    "\n",
    "def f_anchor_i(theta_arr, p_a, p_i):\n",
    "    # conditional prob of anchor i given p_a, p_i\n",
    "    L = len(theta_arr)\n",
    "    # LOS term\n",
    "    los_term = 0\n",
    "    for a_i in range(L):\n",
    "        los_term += f_L(theta_arr[a_i], p_a, p_i) * \\\n",
    "            np.prod([f_NL(theta, p_a, p_i) for theta in theta_arr if theta != theta_arr[a_i]])\n",
    "        # if f_L(theta_arr[a_i], p_a, p_i) == 1:\n",
    "        #     print('los term is', los_term, np.prod([f_NL(theta, p_a, p_i) for theta in theta_arr if theta != theta_arr[a_i]]))\n",
    "    return p_NL * np.prod([f_NL(theta, p_a, p_i) for theta in theta_arr]) + \\\n",
    "        (1 - p_NL) / L * los_term\n",
    "\n",
    "def f_anchor(theta_mtx, p_a, p_i_arr):\n",
    "    # theta_mtx shape: N * L - num of stations by num of ray traces per station\n",
    "    return np.prod([f_anchor_i(theta_mtx[i], p_a, p_i_arr[i]) for i in range(len(theta_mtx))])\n",
    "\n",
    "def m_L(p_a, p_i, tau, sigma):\n",
    "    return stats.norm(tau, sigma).pdf(geodesic(p_a, p_i).m / 3e8)\n",
    "\n",
    "def m_NL(theta_min, theta_max, tau, sigma):\n",
    "    return P_E / theta_max * ( Q(-tau/sigma)- Q((theta_max - tau)/sigma) ) + \\\n",
    "            (1 - P_E) * eta * np.exp(eta * theta_min - eta * tau + .5 * eta**2 * sigma**2) * \\\n",
    "                (Q((theta_min - tau + eta*sigma**2) / sigma) - Q((theta_max - tau + eta*sigma**2) / sigma))\n",
    "\n",
    "def m_i(p_a, p_i, theta_max, tau_arr, sigma_arr):\n",
    "    '''\n",
    "    message update for anchor i\n",
    "    '''\n",
    "    L = len(tau_arr)\n",
    "    theta_min = geodesic(p_a, p_i).m / 3e8\n",
    "    # LOS term\n",
    "    los_term = 0\n",
    "    for a_i in range(L):\n",
    "        los_term += m_L(p_a, p_i, tau_arr[a_i], sigma_arr[a_i]) * \\\n",
    "            np.product([m_NL(theta_min, theta_max, tau_arr[j], sigma_arr[j]) for j in range(0, L) if j != a_i])\n",
    "    \n",
    "    return p_NL * np.prod([m_NL(theta_min, theta_max, tau, sigma) for tau, sigma in zip(tau_arr, sigma_arr)]) + \\\n",
    "        (1 - p_NL) / L * los_term\n",
    "\n",
    "\n",
    "def f_pa(f_p, p_a, p_i_arr, theta_max, tau_mtx, sigma_mtx):\n",
    "    return f_p * np.product([m_i(p_a, p_i, theta_max, tau_arr, sigma_arr) \\\n",
    "        for p_i, tau_arr, sigma_arr in zip(p_i_arr, tau_mtx, sigma_mtx)])\n",
    "    ...\n",
    "\n",
    "def g(p_a, p_i_arr, tau_mtx, sigma_mtx):\n",
    "    '''\n",
    "    Gaussian mixture rings of one agent\n",
    "    '''\n",
    "    N = len(p_i_arr)\n",
    "\n",
    "    def g_i(p_a, p_i, tau_arr, sigma_arr):\n",
    "        '''\n",
    "        Gaussian mixture rings\n",
    "        '''\n",
    "        L = len(tau_arr)\n",
    "\n",
    "        return 1 / L * np.sum([m_L(p_a, p_i, tau,  sigma) for tau, sigma in zip(tau_arr, sigma_arr)])\n",
    "\n",
    "    return np.sum([g_i(p_a, p_i, tau_arr, sigma_arr) for p_i, tau_arr, sigma_arr in zip(p_i_arr, tau_mtx, sigma_mtx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentSampling(object):\n",
    "    def __init__(self,circle=360, S=1000):\n",
    "        self.circle = circle\n",
    "        self.S = S\n",
    "\n",
    "    def sampling(self, p_a, p_i_arr, tau, sigma):\n",
    "        \n",
    "        self.p_a = p_a\n",
    "        self.tau = tau\n",
    "        self.sigma = sigma\n",
    "        self.p_i_arr = p_i_arr\n",
    "\n",
    "        p_a_s = []\n",
    "        weight = []\n",
    "        N = len(self.p_i_arr)\n",
    "\n",
    "        for s in range(self.S):\n",
    "            i = np.random.choice(N) # sample over stations\n",
    "            j = np.random.choice(len(self.tau[i])) # sample over traces between anchor and agent\n",
    "\n",
    "            deg = np.random.choice(self.circle)\n",
    "            p_i = self.p_i_arr[i]\n",
    "\n",
    "            origin = point.Point(p_i)\n",
    "            \n",
    "            tmp = np.random.normal(self.tau[i][j], self.sigma[i][j])\n",
    "            d = tmp * 3e8\n",
    "\n",
    "            f_p = stats.norm(self.tau[i][j], self.sigma[i][j].T).pdf(tmp)\n",
    "            \n",
    "            p_s_loc = geodesic(d/1000).destination(origin, deg)\n",
    "            p_s = np.array([p_s_loc.latitude, p_s_loc.longitude])\n",
    "            fpa = f_pa(f_p, p_s, self.p_i_arr, theta_max, self.tau, self.sigma)\n",
    "            ga = g(p_s, self.p_i_arr, self.tau, self.sigma)\n",
    "\n",
    "            weight.append(np.abs(fpa / ga))\n",
    "            p_a_s.append(p_s)\n",
    "\n",
    "        self.p_a_s = np.array(p_a_s)\n",
    "        self.weight = np.array(weight) / np.sum(weight)\n",
    "        self.p_estim = np.multiply(self.weight, self.p_a_s.T).sum(axis=1)\n",
    "        self.error = geodesic(self.p_a, self.p_estim)\n",
    "        # self.p_estim = self.p_a_s.mean(axis=0)\n",
    "\n",
    "\n",
    "    def visualize(self, ax):\n",
    "        ax.scatter(self.p_a_s[:, 0], self.p_a_s[:, 1], c=self.weight, marker='o')\n",
    "        ax.scatter(self.p_i_arr[:, 0], self.p_i_arr[:, 1])\n",
    "        ax.scatter(self.p_a[0], self.p_a[1], s=320, marker='*')\n",
    "        ax.set_title(f'distance error {self.error} m')\n",
    "        ax.scatter(self.p_estim[0], self.p_estim[1], s=350, marker='x', color='r')\n",
    "        # plot_agent(self.p_a_s)\n",
    "        # plot_agent(self.p_i_arr)\n",
    "        # plot_agent(self.p_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 25\n",
    "idx = np.random.choice(len(p_a_arr), n_a)\n",
    "p_a_set = p_a_arr[idx]\n",
    "fig, axs = plt.subplots(int(np.sqrt(n_a)), int(np.sqrt(n_a)), figsize=(20, 20))\n",
    "axs = axs.flatten()\n",
    "for k in tqdm(range(len(p_a_set))):\n",
    "    p_a = p_a_set[k]\n",
    "    agentsampling = AgentSampling(S=1000)\n",
    "    agentsampling.sampling(p_a, p_i_arr, theta_mtx[idx[k]], sigma_mtx[idx[k]])\n",
    "    agentsampling.visualize(axs[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (computer_vision)",
   "language": "python",
   "name": "pycharm-dac32f44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03573f4b64923689d4251380d9281a39682538eb2277d996e0c4a1b13dbbb109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
